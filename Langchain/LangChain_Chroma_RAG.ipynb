{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14140802",
   "metadata": {},
   "source": [
    "# Chroma - RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e418c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the necessary packaages/modules\n",
    "#!pip install langchain\n",
    "#!pip install sentence-transformers \n",
    "#!pip install langchain-chroma\n",
    "#!pip install langchain-community\n",
    "#!pip install PyPDF2\n",
    "#!pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536bc40",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889216ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PDFPlumberLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0d3fa6",
   "metadata": {},
   "source": [
    "# load the document and split it into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a9f8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PDFPlumberLoader(\"ANN.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cc7355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31aba720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[Document(page_content='what is Neuron - How neuron works\\n1. In a single neuron two operations are performed\\n2. Neuron is Linear combinations and Activations\\n3. If there no activations it is simply a Linear network\\n4. It will not understand and patterns, the deeper thinking is not possible\\n5. In order to get the more patterns, we need to apply Non linearity\\n6. This non linearity is given by activation functions\\n7. The perfect example is sigmoid activation function\\n8. It is look like s curve, which means it is Nonlinear curve\\n9. Now it is the time, understand human brain neuron', metadata={'source': 'ANN.pdf', 'file_path': 'ANN.pdf', 'page': 1, 'total_pages': 5, 'Author': 'Alex Reddy', 'Creator': 'Microsoft® Word 2021', 'CreationDate': \"D:20240502081740+05'30'\", 'ModDate': \"D:20240502081740+05'30'\", 'Producer': 'Microsoft® Word 2021'}), Document(page_content='There are many activation functions are available\\n• Sigmoid\\n• SoftMax\\n• Tanh\\n• ReLU Rectified Linear unit\\n• Leaky ReLU', metadata={'source': 'ANN.pdf', 'file_path': 'ANN.pdf', 'page': 2, 'total_pages': 5, 'Author': 'Alex Reddy', 'Creator': 'Microsoft® Word 2021', 'CreationDate': \"D:20240502081740+05'30'\", 'ModDate': \"D:20240502081740+05'30'\", 'Producer': 'Microsoft® Word 2021'}), Document(page_content=\"Let's calculate the number of parameters for the given architecture:\\n1. Input layer: There are no parameters, only inputs.\\n2. First hidden layer:\\na. Total parameters in this layer: (3×4) +4= 16 parameters.\\n3. Second hidden layer:\\na. Total parameters in this layer: (4×4) +4= 20 parameters.\\n4. Output layer:\\na. Total parameters in this layer: (4×2) +2= 10 parameters.\\nTotal parameters = 36\", metadata={'source': 'ANN.pdf', 'file_path': 'ANN.pdf', 'page': 3, 'total_pages': 5, 'Author': 'Alex Reddy', 'Creator': 'Microsoft® Word 2021', 'CreationDate': \"D:20240502081740+05'30'\", 'ModDate': \"D:20240502081740+05'30'\", 'Producer': 'Microsoft® Word 2021'}), Document(page_content=\"Let's calculate the number of parameters for the given architecture:\\n• Input layer: 10 neurons\\n• First hidden layer: 10 neurons\\n• Second hidden layer: 5 neurons\\n• Output layer: 2 neurons\\nFor each layer, the number of parameters can be calculated as follows:\\n1. Input layer: There are no parameters, only inputs.\\n2. First hidden layer:\\n• Each neuron has 10 weights (one for each input) and 1 bias term.\\n• Total parameters in this layer: (10×10) +10=110 parameters.\\n3. Second hidden layer:\\n• Each neuron has 10 weights (one for each neuron in the previous\\nlayer) and 1 bias term.\\n• Total parameters in this layer: (10×5) +5=55 parameters.\\n4. Output layer:\\n• Each neuron has 5 weights (one for each neuron in the previous\\nlayer) and 1 bias term.\\n• Total parameters in this layer: (5×2) +2=12 parameters.\\nNow, summing up the parameters from all layers:\\n110 parameters in the first hidden layer\\n55 parameters in the second hidden layer\\n12 parameters in the output layer\\n=177 parameters in\", metadata={'source': 'ANN.pdf', 'file_path': 'ANN.pdf', 'page': 4, 'total_pages': 5, 'Author': 'Alex Reddy', 'Creator': 'Microsoft® Word 2021', 'CreationDate': \"D:20240502081740+05'30'\", 'ModDate': \"D:20240502081740+05'30'\", 'Producer': 'Microsoft® Word 2021'})]\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23514c",
   "metadata": {},
   "source": [
    "# Initialize the embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356b8236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91956\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "# Initialize the embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdbeb3",
   "metadata": {},
   "source": [
    "# load it into Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f03ba4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b224576",
   "metadata": {},
   "source": [
    "# query it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10109ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the meaning of neuron\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15c786",
   "metadata": {},
   "source": [
    "# Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32409e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is Neuron - How neuron works\n",
      "1. In a single neuron two operations are performed\n",
      "2. Neuron is Linear combinations and Activations\n",
      "3. If there no activations it is simply a Linear network\n",
      "4. It will not understand and patterns, the deeper thinking is not possible\n",
      "5. In order to get the more patterns, we need to apply Non linearity\n",
      "6. This non linearity is given by activation functions\n",
      "7. The perfect example is sigmoid activation function\n",
      "8. It is look like s curve, which means it is Nonlinear curve\n",
      "9. Now it is the time, understand human brain neuron\n"
     ]
    }
   ],
   "source": [
    "# print results\n",
    "print(docs[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
